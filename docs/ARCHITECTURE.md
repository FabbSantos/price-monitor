# ğŸ—ï¸ Arquitetura do Sistema

## VisÃ£o Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRICE MONITOR SYSTEM                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚      â”‚  Worker.js   â”‚      â”‚ Vercel Cron  â”‚
â”‚  (Cliente)   â”‚      â”‚  (Local)     â”‚      â”‚  (ProduÃ§Ã£o)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚
       â”‚ GET /api/scrape     â”‚ GET /api/scrape    â”‚ Scheduled
       â”‚ (Manual)            â”‚ (Auto a cada 30min)â”‚ (*/30 * * * *)
       â”‚                     â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Next.js API   â”‚
                    â”‚  /api/scrape   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Scrapers    â”‚         â”‚  Notifier    â”‚
        â”‚ (4 lojas)     â”‚         â”‚  (Email)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚           â”‚            â”‚           â”‚
    â–¼           â–¼            â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Amazon â”‚ â”‚Casas B.â”‚ â”‚Mag Luizaâ”‚ â”‚SMTP      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚Server    â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Storage     â”‚
        â”‚ (JSON Files)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         latest-prices.json
         prices-history.json
```

## Fluxo de Dados

### 1ï¸âƒ£ Trigger (Como o scraping Ã© acionado)

**OpÃ§Ã£o A - Manual (Cliente)**:
```
UsuÃ¡rio clica "Atualizar"
    â†“
Browser faz fetch('/api/scrape')
    â†“
Next.js API route processa
```

**OpÃ§Ã£o B - AutomÃ¡tico (Worker)**:
```
setInterval(30 minutos)
    â†“
Worker.js faz fetch('http://localhost:3000/api/scrape')
    â†“
Next.js API route processa
```

**OpÃ§Ã£o C - AutomÃ¡tico (Vercel)**:
```
Vercel Cron (*/30 * * * *)
    â†“
Chama /api/scrape automaticamente
    â†“
Next.js API route processa
```

### 2ï¸âƒ£ Scraping (O que acontece internamente)

```
API /api/scrape recebe requisiÃ§Ã£o
    â†“
Carrega config/products.json
    â†“
Para cada produto:
    â†“
    Para cada loja habilitada:
        â†“
        1. Seleciona scraper apropriado (Factory)
        â†“
        2. Faz requisiÃ§Ã£o HTTP com headers anti-bot
        â†“
        3. Delay aleatÃ³rio (1-3s)
        â†“
        4. Parse HTML com Cheerio
        â†“
        5. Extrai preÃ§o usando seletores CSS
        â†“
        6. Valida e formata preÃ§o
        â†“
        7. Verifica disponibilidade
        â†“
        8. Retorna { price, available, error? }
    â†“
    9. Compara com preÃ§o-alvo
    â†“
    10. Se preÃ§o <= alvo â†’ Notifica via email
    â†“
11. Salva em latest-prices.json
    â†“
12. Adiciona ao prices-history.json
    â†“
13. Retorna resultados ao cliente
```

### 3ï¸âƒ£ NotificaÃ§Ã£o (Email)

```
PreÃ§o <= PreÃ§o-alvo?
    â†“ Sim
JÃ¡ notificou este preÃ§o antes?
    â†“ NÃ£o
Cria email HTML com template
    â†“
Envia via SMTP (Nodemailer)
    â†“
Marca como notificado (cache)
```

### 4ï¸âƒ£ Interface (React)

```
useEffect (componentDidMount)
    â†“
Carrega preÃ§os salvos (GET /api/prices)
    â†“
Carrega histÃ³rico (GET /api/history)
    â†“
setInterval (atualizaÃ§Ã£o periÃ³dica)
    â†“
A cada 30 min: fetch('/api/scrape')
    â†“
Atualiza state com novos preÃ§os
    â†“
React re-renderiza componentes
    â†“
PriceCard detecta preÃ§o <= alvo
    â†“
Aplica classe CSS "animate-price-alert"
    â†“
Card pisca verde!
```

## Componentes Principais

### ğŸ¨ Frontend (React/Next.js)

```
src/app/
â”œâ”€â”€ page.tsx              â†’ PÃ¡gina principal
â”‚   â”œâ”€â”€ useState          â†’ prices, history, loading
â”‚   â”œâ”€â”€ useEffect         â†’ Auto-update loop
â”‚   â””â”€â”€ Components:
â”‚       â”œâ”€â”€ PriceCard     â†’ Card individual por loja
â”‚       â””â”€â”€ PriceHistory  â†’ GrÃ¡fico Recharts
â”‚
â””â”€â”€ layout.tsx            â†’ Layout global
```

### ğŸ”Œ API Routes (Next.js)

```
src/app/api/
â”œâ”€â”€ scrape/route.ts       â†’ Faz scraping completo
â”‚   â”œâ”€â”€ Carrega produtos de config.json
â”‚   â”œâ”€â”€ Itera por lojas
â”‚   â”œâ”€â”€ Chama scrapers
â”‚   â”œâ”€â”€ Compara com metas
â”‚   â”œâ”€â”€ Envia notificaÃ§Ãµes
â”‚   â””â”€â”€ Salva dados
â”‚
â”œâ”€â”€ prices/route.ts       â†’ Retorna Ãºltimos preÃ§os (cache)
â”‚   â””â”€â”€ LÃª latest-prices.json
â”‚
â””â”€â”€ history/route.ts      â†’ Retorna histÃ³rico
    â””â”€â”€ LÃª prices-history.json
```

### ğŸ•·ï¸ Scrapers (Web Scraping)

```
src/lib/scrapers/
â”œâ”€â”€ base.ts               â†’ Classe abstrata
â”‚   â”œâ”€â”€ fetchPage()       â†’ HTTP request com retry
â”‚   â”œâ”€â”€ extractPrice()    â†’ Parse de string â†’ nÃºmero
â”‚   â”œâ”€â”€ delay()           â†’ Sleep anti-bot
â”‚   â””â”€â”€ getRandomUA()     â†’ User-Agent aleatÃ³rio
â”‚
â”œâ”€â”€ amazon.ts             â†’ ImplementaÃ§Ã£o Amazon
â”œâ”€â”€ casasbahia.ts         â†’ ImplementaÃ§Ã£o Casas Bahia
â”œâ”€â”€ magazineluiza.ts      â†’ ImplementaÃ§Ã£o Magazine Luiza
â”œâ”€â”€ mercadolivre.ts       â†’ ImplementaÃ§Ã£o Mercado Livre
â”‚
â””â”€â”€ index.ts              â†’ Factory pattern
    â””â”€â”€ getScraperForStore(id)
```

### ğŸ’¾ Storage (PersistÃªncia)

```
src/lib/storage.ts
â”œâ”€â”€ saveLatestPrices()    â†’ Salva Ãºltima snapshot
â”œâ”€â”€ loadLatestPrices()    â†’ Carrega Ãºltima snapshot
â”œâ”€â”€ addToHistory()        â†’ Append ao histÃ³rico
â”œâ”€â”€ loadHistory()         â†’ Carrega histÃ³rico completo
â””â”€â”€ getProductHistory()   â†’ Filtra por produto/loja

data/
â”œâ”€â”€ latest-prices.json    â†’ Estado atual (sobrescreve)
â””â”€â”€ prices-history.json   â†’ SÃ©rie temporal (append)
```

### ğŸ“§ Notifier (Email)

```
src/lib/notifier.ts
â”œâ”€â”€ Notifier class
â”‚   â”œâ”€â”€ transporter       â†’ Nodemailer SMTP
â”‚   â”œâ”€â”€ notifiedPrices    â†’ Set (cache)
â”‚   â”œâ”€â”€ shouldNotify()    â†’ Verifica se deve notificar
â”‚   â”œâ”€â”€ notify()          â†’ Envia email
â”‚   â””â”€â”€ generateEmailHTML() â†’ Template HTML
â”‚
â””â”€â”€ getNotifier()         â†’ Singleton
```

## PadrÃµes de Design

### 1. Factory Pattern (Scrapers)

```typescript
// Factory cria o scraper correto baseado na loja
const scraper = getScraperForStore('amazon');
// â†’ new AmazonScraper()
```

### 2. Template Method (BaseScraper)

```typescript
abstract class BaseScraper {
  // MÃ©todos comuns implementados
  protected fetchPage() { ... }
  protected extractPrice() { ... }

  // MÃ©todo abstrato - cada scraper implementa
  abstract scrape(url: string): Promise<Result>;
}
```

### 3. Singleton (Notifier)

```typescript
let instance: Notifier | null = null;

export function getNotifier() {
  if (!instance) {
    instance = new Notifier();
  }
  return instance;
}
```

### 4. Strategy Pattern (Storage)

```typescript
// Facilmente substituÃ­vel por DB
interface Storage {
  save(data: PriceData[]): void;
  load(): PriceData[];
}

class JSONStorage implements Storage { ... }
class PostgreSQLStorage implements Storage { ... }
```

## Tratamento de Erros

### Camadas de ProteÃ§Ã£o

```
1. Scraper Level (Retry + Backoff)
   â”œâ”€ Tentativa 1 falhou â†’ aguarda 2s
   â”œâ”€ Tentativa 2 falhou â†’ aguarda 4s
   â””â”€ Tentativa 3 falhou â†’ retorna erro

2. API Level (Try/Catch)
   â”œâ”€ Scraper falhou â†’ retorna { price: null, error: "..." }
   â””â”€ Continua para prÃ³xima loja

3. Worker Level (Process monitoring)
   â”œâ”€ API falhou â†’ loga erro
   â””â”€ Continua loop (nÃ£o mata o processo)

4. Frontend Level (Error boundaries)
   â”œâ”€ API falhou â†’ mostra mensagem
   â””â”€ Permite retry manual
```

## SeguranÃ§a

### Anti-Bot Measures

```
âœ… User-Agent aleatÃ³rio (roda entre 3 opÃ§Ãµes)
âœ… Delays entre requests (1-3 segundos)
âœ… Headers realistas (Accept, Accept-Language, etc)
âœ… Timeout de 15 segundos
âœ… MÃ¡ximo 5 redirects
âœ… Cookies habilitados
```

### Dados SensÃ­veis

```
âœ… .env.local nÃ£o commitado (.gitignore)
âœ… VariÃ¡veis de ambiente no Vercel
âœ… Senhas de email nunca expostas no frontend
âœ… API routes server-side only
```

## Performance

### OtimizaÃ§Ãµes

```
âœ… Scraping paralelo (nÃ£o sequencial)
âœ… Cache de Ãºltimos preÃ§os (nÃ£o refaz scraping)
âœ… HistÃ³rico limitado a 100 entradas por produto
âœ… JSON files (nÃ£o precisa DB para pequeno volume)
âœ… React memo nos componentes
âœ… Lazy loading de grÃ¡ficos
```

### LimitaÃ§Ãµes

```
âš ï¸ 1 scraping por loja = ~2-5 segundos
âš ï¸ 4 lojas Ã— 2 produtos = ~16-40 segundos total
âš ï¸ Vercel timeout: 10 segundos (Hobby) / 60s (Pro)
âš ï¸ Considere upgrade se tiver muitos produtos
```

## Escalabilidade

### Para mais produtos/lojas:

```typescript
// Adicione em config/products.json
{
  "products": [
    { "id": "novo-produto", ... }
  ],
  "stores": [
    { "id": "nova-loja", ... }
  ]
}

// Crie novo scraper
src/lib/scrapers/novaloja.ts

// Registre no factory
src/lib/scrapers/index.ts
```

### Para volume maior:

```
1. Migrar para banco de dados (PostgreSQL/MongoDB)
2. Usar fila de jobs (Bull/BullMQ)
3. Cache com Redis
4. CDN para assets estÃ¡ticos
5. Puppeteer para sites com JS (mais lento mas mais robusto)
```

## Monitoramento

### Logs

```
âœ… Console.log em cada etapa importante
âœ… Timestamp de cada scraping
âœ… DuraÃ§Ã£o de cada operaÃ§Ã£o
âœ… Erros capturados e logados
âœ… Alertas enviados logados
```

### MÃ©tricas Ãºteis:

```
- Taxa de sucesso por loja
- Tempo mÃ©dio de scraping
- NÃºmero de alertas enviados
- Uptime do worker
- Taxa de erro por scraper
```

## Testes

### Como testar:

```bash
# Teste email
npm run test:email

# Teste scrapers
npm run test:scraper

# Teste API manual
curl http://localhost:3000/api/scrape

# Teste worker
npm run worker
```

---

**DÃºvidas sobre a arquitetura?** Consulte os outros docs! ğŸ“š
